{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "74a4f662-eac2-4911-bb84-1f3a01bd30f6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### PySpark Module 5 Assignment\n",
    "\n",
    "```\n",
    "Dataset Description:\n",
    "* dispatching_base_number: The base station ID\n",
    "* date: Date\n",
    "* active_vehicles: The number of active vehicles\n",
    "* trips: Trips\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9542203a-e6e9-4838-918c-dc8778c67ade",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Tasks to be Done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "44d24ceb-4f5a-415f-819d-30f2421dd71d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#configuring spark\n",
    "import findspark\n",
    "findspark.find()\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d51beefb-8c22-4497-9faf-d621259f6dd1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('UberTripsDataAnalysis').master('local[2]').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9bae341e-6393-470e-bb0a-81f2592ef11b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType,StructField,StringType,IntegerType,DateType\n",
    "schema = StructType([\n",
    "    StructField(\"dispatching_base_number\", StringType(), False),\n",
    "    StructField(\"date\", DateType(), True),\n",
    "    StructField(\"active_vehicles\", IntegerType(), True),\n",
    "    StructField(\"trips\", IntegerType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c71498b-e811-4e1a-afee-7845041dc9fd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Load the dataset\n",
    "df=spark\\\n",
    "    .read\\\n",
    "    .format('csv')\\\n",
    "    .option('header',True)\\\n",
    "    .option('dateFormat','M/d/y')\\\n",
    "    .option('mode','dropmalformed')\\\n",
    "    .option('badRecordsPath','./badRecords')\\\n",
    "    .schema(schema)\\\n",
    "    .load('../data/Mod5_uber_data.csv')\n",
    "\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "647bc3bd-2b0f-4836-a151-004a3391d62c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 2. Create a temporary SQL table of the dataset\n",
    "df.createOrReplaceTempView(\"UberTrip\")\n",
    "spark.sql(\"CREATE TEMPORARY VIEW UberTripTemp AS SELECT * FROM UberTrip\")\n",
    "rdd = spark.sql(\"SELECT * FROM UberTripTemp\")\n",
    "rdd.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d33f145-bedf-497b-bde6-05fec4e46727",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3. Print the schema of the table\n",
    "rdd.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5cad91dc-8310-4211-9813-68aff3eab3fd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 4. Print all the distinct ‘dispatching_base_number’\n",
    "distinct_dispatching_base_number=spark.sql('SELECT DISTINCT dispatching_base_number as unique_dispatch_number FROM UberTripTemp')\n",
    "distinct_dispatching_base_number.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "039d62e4-e97c-4d2a-a3da-b03ec5d79d7c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 5. Determine which dispatching base is the busiest based on the number of trips\n",
    "busiest_base=spark.sql('select dispatching_base_number \\\n",
    "                            from UberTripTemp\\\n",
    "                            group by dispatching_base_number\\\n",
    "                            order by sum(trips) desc\\\n",
    "                            limit 1').collect()[0][0]\n",
    "f'Busiest base by trips: {busiest_base}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1561ebfb-b37e-462b-ac34-6a8f77ee8b31",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Alternate method - Column Based Expression\n",
    "import pyspark.sql.functions as f\n",
    "rdd\\\n",
    "    .groupBy('dispatching_base_number')\\\n",
    "    .agg(f.sum('trips')\\\n",
    "    .alias('TotalTrips'))\\\n",
    "    .orderBy(f.desc('TotalTrips'))\\\n",
    "    .limit(1)\\\n",
    "    .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d71d00f-30d7-49a8-9c80-1c51f67d85c8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 6. Determine the five busiest days based on the number of trips in the time range of the data\n",
    "spark.sql('select date, sum(trips) as TotalTrips\\\n",
    "            from UberTripTemp\\\n",
    "            group by date\\\n",
    "            order by sum(trips) desc\\\n",
    "            limit 5')\\\n",
    "            .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c98befa8-ab46-4933-b49f-c2d4127e809d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Alternate method - Window-Rank\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "window=Window.orderBy(f.desc('TotalTrips'))\n",
    "rdd\\\n",
    "    .groupBy('date')\\\n",
    "    .agg(f.sum('trips').alias('TotalTrips'))\\\n",
    "    .withColumn('drank',f.dense_rank().over(window))\\\n",
    "    .where(f.col('drank')<=5)\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88efef42-efa0-4396-beac-d8b943b38068",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 7. Calculate the average number of active vehicles on the base station ‘B02512’\n",
    "average_no_of_active_vehicles=spark.sql('SELECT CEIL(AVG(active_vehicles)) as average_active_vehicles_B02512\\\n",
    "                                            FROM UberTripTemp\\\n",
    "                                            WHERE dispatching_base_number=\"B02512\"')\n",
    "average_no_of_active_vehicles.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bbf79d71-3575-41f4-967c-ea1509f69cda",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# spark.stop()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "pyspark_m5_assignment",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
