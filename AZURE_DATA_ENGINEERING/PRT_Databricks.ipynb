{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Monthwise cumulative revenue using Azure DataBricks.\n",
    "\n",
    "Input Data:\\\n",
    "\n",
    "```\n",
    "+-------+----------+\n",
    "|revenue|      date|\n",
    "+-------+----------+\n",
    "|   3000|2024/01/01|\n",
    "|   2000|2024/01/02|\n",
    "|  50000|2024/01/22|\n",
    "|  45000|2024/02/02|\n",
    "|  13000|2024/03/08|\n",
    "+-------+----------+\n",
    "```\n",
    "\n",
    "Output Data:\\\n",
    "\n",
    "```\n",
    "+-------+----------+-------+------------------+\n",
    "|revenue|      date   |  month  |cumulative_revenue|\n",
    "+-------+----------+-------+------------------+\n",
    "|   3000|2024-01-01|2024-01|              3000|\n",
    "|   2000|2024-01-02|2024-01|              5000|\n",
    "|  50000|2024-01-22|2024-01|             55000|\n",
    "|  45000|2024-02-02|2024-02|             45000|\n",
    "|  13000|2024-03-08|2024-03|             13000|\n",
    "+-------+----------+-------+------------------+\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Databricks Solution Notebook](https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/307084983944736/2902934448424030/5970672593782693/latest.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = [\n",
    "    (3000, \"2024-01-01\"),\n",
    "    (2000, \"2024-01-02\"),\n",
    "    (50000, \"2024-01-22\"),\n",
    "    (45000, \"2024-02-02\"),\n",
    "    (13000, \"2024-03-08\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(input_data, [\"revenue\", \"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F, Window\n",
    "\n",
    "df = df.withColumn(\"month\", F.month(F.col(\"date\")).cast(\"string\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_window = Window.orderBy(F.col(\"date\")).partitionBy(\"month\")\n",
    "df = df.withColumn(\"cumulative_revenue\", F.sum(\"revenue\").over(_window))\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
