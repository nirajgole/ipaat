{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> installations done on 29-07-2023\\\n",
    "> reference [AmpCode-Youtube](https://www.youtube.com/watch?v=OmcSTQVkrvo&ab_channel=AmpCode)\\\n",
    "> reference [sparkbyexamples.com](https://sparkbyexamples.com/spark/spark-hadoop-exception-in-thread-main-java-lang-unsatisfiedlinkerror-org-apache-hadoop-io-nativeio-nativeiowindows-access0ljava-lang-stringiz/)\n",
    "\n",
    "| software   | version |\n",
    "| ---------- | ------- |\n",
    "| windows    | 11      |\n",
    "| jdk        | 20      |\n",
    "| spark      | 3.4.1   |\n",
    "| python     | 3.11    |\n",
    "| \\*\\*hadoop | 3.0.0   |\n",
    "| vscode     | 1.80    |\n",
    "\n",
    "\\*\\* download [winutils.exe and hadoop.dll](https://github.com/steveloughran/winutils/blob/master/hadoop-3.0.0/bin/) from github.\\\n",
    "Create folder (i have created inside `c:\\\\program`) name `hadoop`, create subfolder `bin` and copy `winutils.exe` and `hadoop.dll` to it.\\\n",
    "Also add `hadoop.dll` to `C:\\Windows\\System32`.\n",
    "\n",
    "Setting windows environment variables:\\\n",
    "(User)\n",
    "\n",
    "| variable     | \\*\\* path                                                            |\n",
    "| ------------ | -------------------------------------------------------------------- |\n",
    "| JAVA_HOME    | C:\\Program Files\\Java\\jdk-20                                         |\n",
    "| SPARK_HOME   | C:\\Program Files\\spark\\spark-3.4.1-bin-hadoop3                       |\n",
    "| PYSPARK_HOME | C:\\Users\\Gigabyte\\AppData\\Local\\Programs\\Python\\Python311\\python.exe |\n",
    "| HADOOP_HOME  | C:\\Program Files\\hadoop                                              |\n",
    "\n",
    "\\*\\* subject to change according to your system\n",
    "\n",
    "(System)\\\n",
    "Inside `path` variable add following paths:\n",
    "\n",
    "```scala\n",
    "%SPARK_HOME%\\bin\n",
    "%JAVA_HOME%\\bin\n",
    "%HADOOP_HOME%\\bin\n",
    "```\n",
    "\n",
    "Install python dependencies:\\\n",
    "(run following command on windows powershell)\\\n",
    "\n",
    "`py -m pip install findspark pyspark jupyter`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=pyspark.sql.SparkSession.builder.appName(\"testApp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
